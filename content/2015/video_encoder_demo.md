---
uuid: 1609
title: 如何写一个视频编码器演示篇
status: publish
categories: 编程技术,图形编程
tags: 视频
slug: 
date: 2015-12-24 19:43
---
先前写过《[视频编码原理简介](/blog/archives/1566)》，有朋友问光代码和文字不太真切，能否补充几张图片，今天我们演示一下：

这是第一帧画面：P1（我们的参考帧）

![](https://skywind3000.github.io/images/blog/wp-content/2015/12/output1.png)

这是第二帧画面：P2（需要编码的帧）

![](https://skywind3000.github.io/images/blog/wp-content/2015/12/output2.jpg)

从视频中截取的两张间隔 1-2 秒的画面，和实际情况类似，下面我们参考 P1 进行几次运动搜索：

搜索演示1：搜索 P2 中车辆的车牌在 P1 中最接近的位置（上图 P1，下图 P2）

![](https://skywind3000.github.io/images/blog/wp-content/2015/12/search1.jpg)

这是一个演示程序，鼠标选中 P2 上任意 16×16 的 Block，即可搜索出 P1 上的 BestMatch 宏块。虽然车辆在运动，从远到近，但是依然找到了最接近的宏块坐标。

（点击 more 阅读剩下内容）

<!--more-->

搜索演示2：空中电线交叉位置（上图 P1，下图 P2）

![](https://skywind3000.github.io/images/blog/wp-content/2015/12/search2.jpg)

搜索演示3：报刊停的广告海报

![](https://skywind3000.github.io/images/blog/wp-content/2015/12/search3.jpg)

同样顺利在 P1 中找到最接近 P2 里海报的宏块位置。

图片全搜索：根据 P1 和运动矢量数据（在 P2 中搜索到每一个宏块在 P1 中最相似的位置集合）还原出来的 P2’ ，即完全用 P1 各个位置的宏块拼凑出来最像 P2 的图片P2’，效果如下：

![](https://skywind3000.github.io/images/blog/wp-content/2015/12/output3.png)

仔细观察，有些支离破碎对吧？肯定啊，拼凑出来的东西就是这样，现在我们用 P2` 和 P2 像素相减，得到差分图 D2 = (P2′ – P2) / 2 + 0x80：

![](https://skywind3000.github.io/images/blog/wp-content/2015/12/output4.png)

嗯，这就是 P2` 和 P2 两幅图片的不同处，看到没？基本只有低频了！高频数据少到我们可以忽略，这时用有损压缩方式比较差的效果来保存误差图 D2，只要 5KB 的大小。

接着我们根据运动矢量还原的 P2’ 以及差分图D2来还原新的 P2，NewP2 = P2′ + （D2 – 0x80）* 2：

![](https://skywind3000.github.io/images/blog/wp-content/2015/12/output5.png)

这就是之前支离破碎的 P2` 加上误差 D2 后变成了清晰可见的样子，基本还原了原图P2。

由于 D2 仅仅占 5KB，加上压缩过后的运动矢量不过 7KB，所以参考 P1 我们只需要额外 7KB 的数据量就可以完整表示 P2 了，而如果独立将 P2 用质量尚可的有损压缩方式独立压缩，则至少要去到 50-60KB，这一下节省了差不多 8 倍的空间，这就是所谓运动编码的基本原理。

实际在使用中，参考帧并不一定是前面一帧，也不一定是同一个 GOP 的 I 帧，因为 GOP 间隔较长时，后面的图片离 I 帧变化可能已经很大了，因此常见做法是最近 15 帧中选择一帧误差最小的作为参考帧，虽然彩色画面有 YUV 三个分量，但是大量的预测工作和最有选择通常是根据 Y 分量的灰度帧进行判断的。

再者误差我们保存的是（P2-P2’）/2 + 0x80，实际使用时我们会用更有效率的方式，比如让 [-64,64] 之间的色差精度为 1，[-255,-64], [64, 255] 之间的色差精度为 2-3，这样会更加真实一些。

同时上文很多地方用的是直接 lzma2 进行简单存储，实际使用时一般会引入熵编码，对数据进行一定层次的整理然后再压缩，性能会好不少。

现代视频编码中，除了帧间预测，I 帧还使用了大量帧内预测，而不是完全 dct 量化后编码，前面帧间预测我们使用了参考帧的宏块移动拼凑新帧的方式进行，而所谓帧内预测就是同一幅画面中，未编码部分使用已编码部分拼凑而成。。。。。。。

这些说来话就长了，不过此时相信各位理解起 MPEG2 来会发现并不是什么太深奥的东西，MPEG2 的各项规范熟悉了，H.264 也就好说了，读资料的同时自己做一下试验参照理论，应该能轻松很多。

